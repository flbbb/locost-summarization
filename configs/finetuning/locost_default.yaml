train:
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  effective_batch_size: 128
  n_epochs: 60
  seed: 42
  lr: 0.0005
  lr_end: null
  ratio_warmup: null
  warmup_steps: 10000
  label_smoothing: 0.0
  logging_steps: 100
  save_steps: 500
  precision: "bf16"
  scheduler: "constant"
  optimizer: "adamw"
  check_val_epoch: 1

model:
  dropout_rate: 0.1
  max_length: 4096

